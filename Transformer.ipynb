{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijeet/miniconda3/envs/TRIZ/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_epochs = 500\n",
    "model_no = 'transformer_with_word2vec'\n",
    "exp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5500, 1])\n"
     ]
    }
   ],
   "source": [
    "# With square kernels and equal stride\n",
    "# m = nn.Conv2d(5500, 5500, 1, stride=1)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv1d(5500, 5500, 1, stride=1)\n",
    "# # non-square kernels and unequal stride and with padding and dilation\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 5500, 1)\n",
    "output = m(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=100, nheads=5, num_encoder_layers=5, num_decoder_layers=5, avg_words = 5500):\n",
    "        super(custom_transformer, self).__init__()\n",
    "#         self.transformer = nn.Transformer(hidden_dim, nheads, num_encoder_layers, num_decoder_layers, \n",
    "#                                           batch_first=True, activation=\"relu\")\n",
    "        self.encoder = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nheads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder, num_layers = num_encoder_layers)\n",
    "        \n",
    "        self.decoder = nn.TransformerDecoderLayer(d_model=hidden_dim, nhead=nheads, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder, num_layers = num_decoder_layers)\n",
    "        \n",
    "#         self.linear1 = nn.Linear(hidden_dim*avg_words, hidden_dim*avg_words, bias=True)\n",
    "#         self.one_D_conv = nn.Conv2d(hidden_dim*avg_words, hidden_dim*avg_words, 1, stride=1)\n",
    "        self.relu_layer = nn.ReLU()\n",
    "        self.sigmoid_layer = nn.Sigmoid()\n",
    "        \n",
    "    def positionalencoding1d(self, d_model, length):\n",
    "        \"\"\"\n",
    "        :param d_model: dimension of the model\n",
    "        :param length: length of positions\n",
    "        :return: length*d_model position matrix\n",
    "        \"\"\"\n",
    "        if d_model % 2 != 0:\n",
    "            raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
    "                             \"odd dim (got dim={:d})\".format(d_model))\n",
    "        pe = torch.zeros(length, d_model)\n",
    "        position = torch.arange(0, length).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) *\n",
    "                             -(math.log(10000.0) / d_model)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        return pe\n",
    "\n",
    "    def forward(self, feat_input):\n",
    "        feat_input = feat_input.flatten(2)\n",
    "#         print(feat_input.shape)\n",
    "#         print(self.positionalencoding1d(self.hidden_dim, feat_input.shape[-2]).repeat(feat_input.shape[0], feat_input.shape[1], feat_input.shape[2]).is_cuda)\n",
    "#         feat_input += self.positionalencoding1d(self.hidden_dim, feat_input.shape[-2]).repeat(feat_input.shape[0], feat_input.shape[1], feat_input.shape[2])\n",
    "#         features = self.transformer(feat_input.cuda(), self.learnable_query.repeat(feat_input.shape[0], 1, 1))\n",
    "        enc_features = self.transformer_encoder(feat_input)\n",
    "            \n",
    "        dec_features = self.transformer_decoder(feat_input, enc_features)\n",
    "#         a.unsqueeze(2)\n",
    "#         print(dec_features.flatten(1).shape)\n",
    "#         print(dec_features.flatten(1).unsqueeze(2).shape)\n",
    "#         features = self.linear1(dec_features.flatten(1))\n",
    "        dec_features = self.sigmoid_layer(features)\n",
    "\n",
    "        return dec_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params: 5674176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijeet/miniconda3/envs/TRIZ/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "new_model = custom_transformer()\n",
    "# new_model.to(device)\n",
    "print(\"Total trainable params:\", torch.nn.utils.parameters_to_vector([p for p in new_model.parameters() if p.requires_grad]).numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_transformer(\n",
       "  (encoder): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    (dropout3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-4): 5 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
       "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu_layer): ReLU()\n",
       "  (sigmoid_layer): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class dataset_loader(Dataset):\n",
    "    \n",
    "    def __init__(self, corpus_dir, word2vec_dir):\n",
    "        self.word2vec_all = open(word2vec_dir, 'r')\n",
    "        self.word2vec_all = json.load(self.word2vec_all)\n",
    "        self.dataset = pd.read_excel(corpus_dir + 'generated_data.xlsx')\n",
    "        self.dataset = self.dataset.dropna()\n",
    "        self.text = self.dataset['text']\n",
    "        self.label = self.dataset['labels']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.text.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row_text = self.text[idx].lower().replace('\\n', ' ').split()\n",
    "        row_label = eval(self.label[idx])\n",
    "#         print(row_label.shape, row_text.shape)\n",
    "        word2vec_matrix = []\n",
    "        \n",
    "        for count, i in enumerate(row_text):\n",
    "            try:\n",
    "                word2vec_matrix.append(np.array(self.word2vec_all[i]))\n",
    "                if count == 5000:\n",
    "                    break\n",
    "            except:\n",
    "                word2vec_matrix.append(np.zeros(100))\n",
    "        \n",
    "        for i in range(5000 - len(word2vec_matrix)):\n",
    "            word2vec_matrix.append(np.zeros(100))\n",
    "            \n",
    "#         print(len(word2vec_matrix))\n",
    "\n",
    "        for next_count, i in enumerate(row_label):\n",
    "            try:\n",
    "                word2vec_matrix.append(np.array(self.word2vec_all[i]))\n",
    "                if next_count == 499:\n",
    "                    break\n",
    "            except:\n",
    "                word2vec_matrix.append(np.zeros(100))\n",
    "            \n",
    "        for i in range(499 - next_count):\n",
    "            word2vec_matrix.append(np.zeros(100))\n",
    "\n",
    "#         print(len(word2vec_matrix))\n",
    "        \n",
    "        output = {'text_label': np.array(word2vec_matrix)}\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset_loader(corpus_dir='/home/abhijeet/Desktop/TRIZ/All_data/CPC Data/',\n",
    "                              word2vec_dir='/home/abhijeet/Desktop/TRIZ/word_vectors.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(train_data))\n",
    "for i in range(len(train_data)):\n",
    "    sample = train_data[i]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = torch.utils.data.RandomSampler(train_data)\n",
    "\n",
    "dataloader_train = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def criterion(predicted, target):\n",
    "    \"\"\"\n",
    "    Compute the Kullback-Leibler Divergence loss between two probability distributions.\n",
    "\n",
    "    Args:\n",
    "        p (torch.Tensor): True distribution (e.g., ground truth probabilities).\n",
    "        q (torch.Tensor): Approximate distribution (e.g., predicted probabilities).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: KL Divergence loss.\n",
    "    \"\"\"\n",
    "#     return F.kl_div(F.log_softmax(target, dim=1), F.softmax(predicted, dim=1), reduction='batchmean')\n",
    "    return F.kl_div(predicted, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.to(device)\n",
    "optimizer = torch.optim.SGD(new_model.parameters(), lr=0.009, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Step:   0%|                                          | 0/173749 [00:00<?, ?it/s]\u001b[A/home/abhijeet/miniconda3/envs/TRIZ/lib/python3.8/site-packages/torch/nn/functional.py:2949: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n",
      "\n",
      "Epoch: 1 Step:   0%|                                | 1/173749 [00:00<8:00:04,  6.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5500, 100])\n",
      "\r",
      "Step: 1 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Step:   0%|                                | 3/173749 [00:00<4:06:29, 11.75it/s]\u001b[A\n",
      "Epoch: 1 Step:   0%|                                | 5/173749 [00:00<4:07:11, 11.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Step: 2 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "\r",
      "Step: 3 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "\r",
      "Step: 4 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Step:   0%|                                | 7/173749 [00:00<4:03:50, 11.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Step: 5 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "\r",
      "Step: 6 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "\r",
      "Step: 7 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Step:   0%|                                | 9/173749 [00:00<4:04:22, 11.85it/s]\u001b[A\n",
      "Epoch: 1 Step:   0%|                               | 11/173749 [00:00<4:01:16, 12.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "Step: 9 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "Step: 10 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "Step: 11 Training Loss: nan Validation Loss: 0.0 Epoch loss: nantorch.Size([1, 5500, 100])\n",
      "Step: 12 Training Loss: nan Validation Loss: 0.0 Epoch loss: nan"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Model Error: Encountered 11 nan loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_nans \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Error: Encountered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_nans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nan loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     num_nans \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Model Error: Encountered 11 nan loss"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    num_nans = 0\n",
    "    running_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    print(f\"\\nEpoch: {epoch+1}\")\n",
    "    inner_pbar = tqdm(total=len(dataloader_train), position=1, leave=False, ascii=True, desc=f\"Epoch: {epoch+1} Step\")\n",
    "\n",
    "    for i, data in enumerate(dataloader_train, 1):\n",
    "        features = data['text_label']\n",
    "        features = features.type(torch.FloatTensor)\n",
    "        features = features.to(device)\n",
    "#         print(features.is_cuda)\n",
    "        y_ground_truth = features\n",
    "        optimizer.zero_grad()\n",
    "        print(features.shape)\n",
    "        preds = new_model(features)\n",
    "        \n",
    "        loss = criterion(predicted=preds, target=y_ground_truth)\n",
    "\n",
    "        inner_pbar.update(1)\n",
    "        \n",
    "        running_loss += loss.detach().item()\n",
    "\n",
    "        print(f\"\\rStep: {i} Training Loss: {loss.item()} Validation Loss: {val_loss} Epoch loss: {running_loss/(i)}\", end=\"\")\n",
    "        # print(f\"\\rStep: {i} Training Loss: {loss.item()} Validation Loss: {val_loss} Nans: {num_nans}\")\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            if num_nans > 10:\n",
    "                raise RuntimeError(f\"Model Error: Encountered {num_nans} nan loss\")\n",
    "            num_nans += 1\n",
    "            continue\n",
    "        # loss.requires_grad = True\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    inner_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Step:   0%|                               | 12/173749 [00:19<4:01:16, 12.00it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 32, 512)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "out = transformer_decoder(tgt, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRIZ",
   "language": "python",
   "name": "triz"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
